{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iPenguin - Semantic Scholar Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allows async co-routines to work inside of jupyter notebook\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHING_DIR = 's2_cache'\n",
    "CACHING_DIR = pathlib.Path(CACHING_DIR).resolve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create the S2 Handler Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TELF.pre_processing.iPenguin.SemanticScholar import SemanticScholar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found S2_KEY environment variable\n"
     ]
    }
   ],
   "source": [
    "if \"S2_KEY\" in os.environ:\n",
    "    print(\"Found S2_KEY environment variable\")\n",
    "    API_KEY = os.environ[\"S2_KEY\"]\n",
    "else:\n",
    "    print(\"Variable does not exist. Export SemanticScholar API key on your environment using the variable name S2_KEY.\")\n",
    "    API_KEY = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = SemanticScholar(\n",
    "    key = API_KEY,\n",
    "    mode = 'fs',         # file system caching mode (default)\n",
    "    name = CACHING_DIR,  # where to cache the files\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Use the S2 Handler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Lookup Papers by their ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAPERS = [\n",
    "    '59e4d6475c41096befeafec55ea5ad97432de527', \n",
    "    '9806df234e723cd348112f348ee0724f52bc8f73', \n",
    "]\n",
    "\n",
    "len(PAPERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[S2]: Found 2 papers in 0.43s\n"
     ]
    }
   ],
   "source": [
    "count = s2.count(PAPERS, mode='paper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 44384.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2 entries, 0 to 1\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   s2id            2 non-null      object\n",
      " 1   doi             2 non-null      object\n",
      " 2   year            2 non-null      int64 \n",
      " 3   title           2 non-null      object\n",
      " 4   abstract        2 non-null      object\n",
      " 5   s2_authors      2 non-null      object\n",
      " 6   s2_author_ids   2 non-null      object\n",
      " 7   citations       2 non-null      object\n",
      " 8   references      2 non-null      object\n",
      " 9   num_citations   2 non-null      int64 \n",
      " 10  num_references  2 non-null      int64 \n",
      "dtypes: int64(3), object(8)\n",
      "memory usage: 308.0+ bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[S2]: Finished downloading 2 papers for given query in 0.95s\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "df, paper_ids = s2.search(PAPERS, mode='paper')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['59e4d6475c41096befeafec55ea5ad97432de527',\n",
       " '9806df234e723cd348112f348ee0724f52bc8f73']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_ids[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Get Papers by Author ID(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTHORS = [\n",
    "    '2025666',     # Boian Alexandrov\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the **maximum** number of papers that will be returned from this search. Note that Semantic Scholar has no support for quickly finding the total number of papers for a group of authors. The count is computed by taking the sum of the number of papers for each author. This means that the same paper will be counted multiple times if the authors being examined are co-authors. Use the output of ```SemanticScholar.count(*, mode='author')``` as an upper bound on how many papers will be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[S2]: Found 147 papers in 1.26s\n"
     ]
    }
   ],
   "source": [
    "count = s2.count(AUTHORS, mode='author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 187.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 147 entries, 0 to 146\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   s2id            147 non-null    object\n",
      " 1   doi             132 non-null    object\n",
      " 2   year            147 non-null    int64 \n",
      " 3   title           147 non-null    object\n",
      " 4   abstract        95 non-null     object\n",
      " 5   s2_authors      147 non-null    object\n",
      " 6   s2_author_ids   147 non-null    object\n",
      " 7   citations       107 non-null    object\n",
      " 8   references      116 non-null    object\n",
      " 9   num_citations   147 non-null    int64 \n",
      " 10  num_references  147 non-null    int64 \n",
      "dtypes: int64(3), object(8)\n",
      "memory usage: 12.8+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[S2]: Finished downloading 147 papers for given query in 1.65s\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done   2 out of  12 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done  12 out of  12 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "df, paper_ids = s2.search(AUTHORS, mode='author')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Get Papers by Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establish how many papers can be found for some query on S2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[S2]: Found 1,206,928 papers in 2.14s\n"
     ]
    }
   ],
   "source": [
    "count = s2.count('tensor decomposition', mode='query')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```SemanticScholar.search()``` function takes an optional argument ```n```. This argument sets an upper limit on how many papers to download. SemanticScholar search ranks the results by relevancy so the top ```n``` most \"relevant\" papers are found for a given query. By default ```n``` is set to 100 but it can be set to any positive integer value. Set ```n``` equal to 0 download all available papers for a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   s2id            5 non-null      object\n",
      " 1   doi             4 non-null      object\n",
      " 2   year            5 non-null      int64 \n",
      " 3   title           5 non-null      object\n",
      " 4   abstract        5 non-null      object\n",
      " 5   s2_authors      5 non-null      object\n",
      " 6   s2_author_ids   5 non-null      object\n",
      " 7   citations       5 non-null      object\n",
      " 8   references      5 non-null      object\n",
      " 9   num_citations   5 non-null      int64 \n",
      " 10  num_references  5 non-null      int64 \n",
      "dtypes: int64(3), object(8)\n",
      "memory usage: 572.0+ bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[S2]: Finished downloading 5 papers for given query in 3.39s\n",
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "df, paper_ids = s2.search('tensor decomposition', mode='query', n=5)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paper_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get all Cached Papers and Form Single DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```SemanticScholar.get_df``` method can be used to access the file system cache directly. This function also takes an optional argument ```targets```. If None (the default) all papers in the cache directory are returned. Otherwise ```targets``` is expected to be an iterable (list, set, tuple) of Semantic Scholar IDs to be fetched from the cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 646 entries, 0 to 645\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   s2id            646 non-null    object \n",
      " 1   doi             559 non-null    object \n",
      " 2   year            645 non-null    float64\n",
      " 3   title           646 non-null    object \n",
      " 4   abstract        518 non-null    object \n",
      " 5   s2_authors      645 non-null    object \n",
      " 6   s2_author_ids   645 non-null    object \n",
      " 7   citations       604 non-null    object \n",
      " 8   references      604 non-null    object \n",
      " 9   num_citations   646 non-null    int64  \n",
      " 10  num_references  646 non-null    int64  \n",
      "dtypes: float64(1), int64(2), object(8)\n",
      "memory usage: 55.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df, paper_ids = SemanticScholar.get_df(CACHING_DIR)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TELF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
