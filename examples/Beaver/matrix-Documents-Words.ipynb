{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f6b4dd2",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "280d65bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 940 entries, 0 to 939\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   eid             940 non-null    object\n",
      " 1   title           940 non-null    object\n",
      " 2   year            940 non-null    int64 \n",
      " 3   abstract        940 non-null    object\n",
      " 4   authors         940 non-null    object\n",
      " 5   author_ids      940 non-null    object\n",
      " 6   references      843 non-null    object\n",
      " 7   clean_abstract  940 non-null    object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 58.9+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../../data/sample.csv\")\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07669d4b",
   "metadata": {},
   "source": [
    "# Build Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcb5b592",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TELF.pre_processing import Beaver\n",
    "\n",
    "beaver = Beaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8de42da",
   "metadata": {},
   "source": [
    "First let's get our vocabulary from the documents words matrix. **This step is optional!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51e5786f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.5 ms, sys: 2.2 ms, total: 36.7 ms\n",
      "Wall time: 35.6 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "467"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings = {\n",
    "    \"dataset\":df,\n",
    "    \"target_column\":\"clean_abstract\",\n",
    "    \"min_df\":10,\n",
    "    \"max_df\":0.5,\n",
    "}\n",
    "\n",
    "%time vocabulary = beaver.get_vocabulary(**settings)\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfff9907",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maksim/Desktop/Code/T-ELF_public/TELF/pre_processing/Beaver/beaver.py:867: UserWarning: Vocabulary was extended!\n",
      "  warnings.warn(\"Vocabulary was extended!\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<940x471 sparse matrix of type '<class 'numpy.float32'>'\n",
       " \twith 72655 stored elements in Compressed Sparse Row format>,\n",
       " array(['128pb', '2018', '32x', 'aberration', 'ability', 'ablation',\n",
       "        'ablator', 'able', 'abstain', 'accelerate', 'accuracy', 'accurate',\n",
       "        'acquisition', 'activity', 'addition', 'address', 'adoption',\n",
       "        'aggregate', 'aid', 'alamos', 'allow', 'alternate', 'analogous',\n",
       "        'analysis', 'analyst', 'analytic', 'anomaly', 'apply', 'approach',\n",
       "        'approximately', 'archive', 'art', 'arxiv', 'associate',\n",
       "        'asynchronously', 'attack', 'author', 'automatic', 'available',\n",
       "        'base', 'baseline', 'batch', 'behavior', 'belong', 'benchmark',\n",
       "        'benign', 'bias', 'block', 'bottleneck', 'break', 'bronze',\n",
       "        'build', 'bulk', 'call', 'cancer', 'canonical', 'capability',\n",
       "        'catalog', 'category', 'cause', 'central', 'certain', 'challenge',\n",
       "        'characterization', 'citation', 'class', 'classification',\n",
       "        'classify', 'client', 'cluster', 'coherent', 'collaborative',\n",
       "        'collective', 'combine', 'common', 'communication', 'competitive',\n",
       "        'completion', 'composition', 'compute', 'condition', 'connect',\n",
       "        'consider', 'constructively', 'consume', 'context', 'contribute',\n",
       "        'control', 'copy', 'core', 'corpora', 'corpus', 'correspond',\n",
       "        'cost', 'costly', 'county', 'coverage', 'cpu', 'create', 'crucial',\n",
       "        'cuda', 'current', 'curve', 'cyber', 'cybersecurity', 'd100',\n",
       "        'damage', 'dangerous', 'dataset', 'dataset6', 'date', 'decompose',\n",
       "        'decomposition', 'defense', 'demonstrate', 'dense', 'density',\n",
       "        'dependence', 'deploy', 'describe', 'design', 'detail', 'detect',\n",
       "        'determination', 'develop', 'deviate', 'device', 'differently',\n",
       "        'difficult', 'dimensionality', 'discovery', 'disease', 'disruptor',\n",
       "        'distinct', 'distribute', 'dna', 'document', 'early', 'education',\n",
       "        'efficient', 'electrical', 'embed', 'ember', 'emerge', 'enable',\n",
       "        'enhance', 'ensure', 'entity', 'equipment', 'error', 'essential',\n",
       "        'establish', 'estimation', 'evaluation', 'even', 'event',\n",
       "        'exabyte', 'examine', 'exist', 'expand', 'expect', 'expensive',\n",
       "        'experiment', 'expert', 'exploit', 'explore', 'extend', 'extract',\n",
       "        'extreme', 'face', 'faceted', 'facilitate', 'family', 'feature',\n",
       "        'fedcf', 'federate', 'field', 'file', 'filter', 'find', 'fine',\n",
       "        'follow', 'football', 'framework', 'frequency', 'furthermore',\n",
       "        'gain', 'generate', 'genome', 'good', 'gpu', 'gpus', 'grain',\n",
       "        'gram', 'greater', 'grid', 'group', 'grow', 'handpick', 'help',\n",
       "        'heterogeneous', 'hide', 'hierarchical', 'high', 'highly', 'hnmfk',\n",
       "        'host', 'human', 'idea', 'identification', 'identify', 'idf',\n",
       "        'ignore', 'imbalance', 'implementation', 'improve', 'include',\n",
       "        'incorporate', 'information', 'inherit', 'initial', 'innovation',\n",
       "        'insight', 'interaction', 'intermediate', 'introduce', 'intrusion',\n",
       "        'invasive', 'inverse', 'item', 'jargon', 'joint', 'jointly',\n",
       "        'keep', 'key', 'know', 'label', 'laboratory', 'lack', 'large',\n",
       "        'latency', 'latent', 'library', 'likely', 'literature', 'loop',\n",
       "        'los', 'low', 'machine', 'maintain', 'majority', 'malicious',\n",
       "        'malware', 'market', 'matter', 'meaningful', 'medal', 'memory',\n",
       "        'method', 'miss', 'mitigation', 'mix', 'modal', 'modern',\n",
       "        'monitor', 'movielen', 'multi', 'multiplication', 'mutation',\n",
       "        'name', 'narrow', 'national', 'naturally', 'nearly', 'need',\n",
       "        'nervous', 'network', 'nmfk', 'node', 'normal', 'novel', 'novelly',\n",
       "        'nvidia', 'obtain', 'occur', 'often', 'operation', 'optimize',\n",
       "        'option', 'organization', 'otherwise', 'outage', 'overlap',\n",
       "        'paper', 'parallel', 'partnership', 'pattern', 'permanent',\n",
       "        'personalize', 'phenomenon', 'platform', 'poisson', 'politic',\n",
       "        'polyadic', 'poorly', 'post', 'potential', 'power', 'practicality',\n",
       "        'pre', 'precise', 'prediction', 'preliminary', 'preserve',\n",
       "        'previously', 'principal', 'prior', 'privacy', 'probabilistic',\n",
       "        'problem', 'processor', 'production', 'project', 'prominent',\n",
       "        'prone', 'propose', 'provide', 'prune', 'public', 'quality',\n",
       "        'quantity', 'rapid', 'rare', 'real', 'realistic', 'recently',\n",
       "        'recognition', 'recognize', 'recommender', 'reduce', 'reduction',\n",
       "        'regression', 'regularly', 'rejection', 'relatively', 'rely',\n",
       "        'repeat', 'report', 'represent', 'research', 'result', 'retrieval',\n",
       "        'review', 'risk', 'robust', 'sample', 'save', 'scada',\n",
       "        'scalability', 'scale', 'science', 'scientific', 'score',\n",
       "        'security', 'seed', 'selection', 'semantic', 'semi', 'senmfk',\n",
       "        'sensor', 'separate', 'serve', 'service', 'set', 'setup',\n",
       "        'severity', 'share', 'shoot', 'shortcoming', 'showcase',\n",
       "        'signature', 'significant', 'significantly', 'similar',\n",
       "        'similarly', 'singular', 'size', 'smarttensor', 'smooth', 'soccer',\n",
       "        'software', 'solution', 'space', 'sparse', 'sparsity', 'specific',\n",
       "        'specimen', 'speedup', 'spend', 'sport', 'stage', 'state',\n",
       "        'static', 'statistical', 'strategy', 'stream', 'strong',\n",
       "        'structure', 'study', 'sub', 'subject', 'substantial',\n",
       "        'substation', 'subtopic', 'successfully', 'sufficiently', 'super',\n",
       "        'supervise', 'supervisory', 'support', 'suppress', 'surpass',\n",
       "        'svd', 'synthetically', 'system', 'take', 'target', 'technique',\n",
       "        'tennis', 'tensor', 'terabyte', 'test', 'text', 'theme', 'threat',\n",
       "        'tile', 'time', 'together', 'token', 'tool', 'topic',\n",
       "        'traditional', 'train', 'transfer', 'transmission', 'treat',\n",
       "        'truncate', 'type', 'typically', 'understand', 'unify', 'unknown',\n",
       "        'unseen', 'unsupervised', 'user', 'utilization', 'value',\n",
       "        'variable', 'vector', 'visualize', 'vocabulary', 'ware', 'warfare',\n",
       "        'weak', 'well', 'window', 'winner', 'wireless', 'word', 'world',\n",
       "        'yield'], dtype=object))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings = {\n",
    "    \"dataset\":df,\n",
    "    \"target_column\":\"clean_abstract\",\n",
    "    \"options\":{\"min_df\": 5, \"max_df\": 0.5, \"vocabulary\":vocabulary},\n",
    "    \"matrix_type\":\"tfidf\",\n",
    "    \"highlighting\":['aberration', 'ability', 'ablation', 'ablator', 'able'],\n",
    "    \"weights\":2,\n",
    "    \"save_path\":\"./\"\n",
    "}\n",
    "\n",
    "beaver.documents_words(**settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70dc8b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<940x470 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 72279 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.sparse as ss\n",
    "\n",
    "# load the saved file which is in Sparse COO format\n",
    "X_csr_sparse = ss.load_npz(\"documents_words.npz\")\n",
    "X_csr_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb5b8a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chop_chop_rows(X, n=1):\n",
    "    m_rows = X.shape[0]\n",
    "    chunk_size = int(m_rows/n)\n",
    "    chunks = []\n",
    "    \n",
    "    for idx in range(n):\n",
    "        start = idx*chunk_size\n",
    "        if idx == (n-1):\n",
    "            end = m_rows\n",
    "        else:\n",
    "            end = (idx*chunk_size)+chunk_size\n",
    "        chunks.append(X[start:end])\n",
    "        \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "151878ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<235x470 sparse matrix of type '<class 'numpy.float32'>'\n",
       " \twith 17780 stored elements in Compressed Sparse Row format>,\n",
       " <235x470 sparse matrix of type '<class 'numpy.float32'>'\n",
       " \twith 18674 stored elements in Compressed Sparse Row format>,\n",
       " <235x470 sparse matrix of type '<class 'numpy.float32'>'\n",
       " \twith 17642 stored elements in Compressed Sparse Row format>,\n",
       " <235x470 sparse matrix of type '<class 'numpy.float32'>'\n",
       " \twith 18183 stored elements in Compressed Sparse Row format>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chop_chop_rows(X_csr_sparse, n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f7b4cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
