{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TELF.pipeline import BlockManager\n",
    "from TELF.pipeline.blocks import (\n",
    "    DataBundle,\n",
    "    SAVE_DIR_BUNDLE_KEY,\n",
    "    SOURCE_DIR_BUNDLE_KEY,\n",
    "    VultureCleanBlock,\n",
    "    BeaverVocabBlock,\n",
    "    BeaverDocWordBlock,\n",
    "    NMFkBlock,\n",
    "    HNMFkBlock,\n",
    "    SemanticHNMFkBlock,\n",
    "    FunctionBlock,\n",
    "    ClusteringAnalyzerBlock,\n",
    "    LoadDfBlock,\n",
    "    LabelAnalyzerBlock\n",
    ")\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as ss\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 19 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   eid               50 non-null     object \n",
      " 1   s2id              50 non-null     object \n",
      " 2   doi               50 non-null     object \n",
      " 3   title             50 non-null     object \n",
      " 4   abstract          50 non-null     object \n",
      " 5   year              50 non-null     int64  \n",
      " 6   authors           50 non-null     object \n",
      " 7   author_ids        50 non-null     object \n",
      " 8   affiliations      50 non-null     object \n",
      " 9   funding           5 non-null      object \n",
      " 10  PACs              8 non-null      object \n",
      " 11  publication_name  50 non-null     object \n",
      " 12  subject_areas     50 non-null     object \n",
      " 13  s2_authors        50 non-null     object \n",
      " 14  s2_author_ids     50 non-null     object \n",
      " 15  citations         45 non-null     object \n",
      " 16  references        38 non-null     object \n",
      " 17  num_citations     50 non-null     int64  \n",
      " 18  num_references    50 non-null     float64\n",
      "dtypes: float64(1), int64(2), object(16)\n",
      "memory usage: 7.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(Path(\"..\") / \"..\" / \"..\" /\"data\" / \"sample2.csv\").head(50)\n",
    "df.info()\n",
    "\n",
    "EXAMPLE_OUTPUT = Path( \"example_results\") / 'post_process_example' \n",
    "bundle = DataBundle({'Default.df':df, \n",
    "                     SAVE_DIR_BUNDLE_KEY: EXAMPLE_OUTPUT,\n",
    "                     SOURCE_DIR_BUNDLE_KEY: EXAMPLE_OUTPUT})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VultureClean] needs → (df)   provides → (df, vulture_steps)\n",
      "[BeaverVocab] needs → (df)   provides → (vocabulary)\n",
      "[BeaverDW] needs → (df, vocabulary)   provides → (X)\n",
      "[NMFk] needs → (X)   provides → (nmfk_model, nmfk_model_path)\n",
      "[HNMFk] needs → (X)   provides → (hnmfk_model, saved_path)\n",
      "[NMFAnalyzer] needs → (df, nmfk_model, nmfk_model_path, vocabulary)   provides → (clusters_path)\n",
      "[HNMFAnalyzer] needs → (df, hnmfk_model, vocabulary)   provides → (clusters_path)\n",
      "[ClusterOnlyAnalyzer] needs → (df)   provides → (clusters_path)\n",
      "[NoClusterAnalyzer] needs → (df)   provides → (clusters_path)\n",
      "[NMFLabels] needs → (NMFAnalyzer.clusters_path)   provides → (result, label_paths)\n",
      "[HNMFkLabels] needs → (HNMFAnalyzer.clusters_path)   provides → (result, label_paths)\n",
      "[ClusterOnlyLabels] needs → (ClusterOnlyAnalyzer.clusters_path)   provides → (result, label_paths)\n",
      "[NoClusterLabels] needs → (NoClusterAnalyzer.clusters_path)   provides → (result, label_paths)\n",
      "[LoadDF] needs → (dir)   provides → (df, df_paths)\n"
     ]
    }
   ],
   "source": [
    "vulture_block = VultureCleanBlock( init_settings={\"n_jobs\":1})\n",
    "vocab_block = BeaverVocabBlock()\n",
    "matrix_block = BeaverDocWordBlock()\n",
    "factor_block = NMFkBlock(init_settings={\"n_perturbs\": 2, \"n_iters\":2})\n",
    "hfactor_block = HNMFkBlock( init_settings={\"nmfk_params\":{\"n_perturbs\": 2, \"n_iters\":2}})\n",
    "\n",
    "nmfk_analyzer = ClusteringAnalyzerBlock(\n",
    "    tag='NMFAnalyzer',\n",
    "    mode='nmf'\n",
    ")\n",
    "hnmfk_analyzer = ClusteringAnalyzerBlock(\n",
    "    tag='HNMFAnalyzer',\n",
    "    mode='hnmf'\n",
    ")\n",
    "extracted_cluster_only_nmfk_analyzer = ClusteringAnalyzerBlock(\n",
    "    tag='ClusterOnlyAnalyzer',\n",
    "    call_settings={\"cluster_col\": \"cluster\"},\n",
    "    mode='label'\n",
    ")\n",
    "no_cluster_analyzer = ClusteringAnalyzerBlock(\n",
    "    tag='NoClusterAnalyzer',\n",
    "    mode=None\n",
    ")\n",
    "\n",
    "# ── after importing LabelAnalyzerBlock ──────────────────────────────────────\n",
    "nmf_labels = LabelAnalyzerBlock(\n",
    "    tag   = \"NMFLabels\",\n",
    "    needs = (\"NMFAnalyzer.clusters_path\",)        # ← csv path from NMFAnalyzer\n",
    ")\n",
    "\n",
    "hnmfk_labels = LabelAnalyzerBlock(\n",
    "    tag   = \"HNMFkLabels\",\n",
    "    needs = (\"HNMFAnalyzer.clusters_path\",)       # ← list of csv paths from HNMFAnalyzer\n",
    ")\n",
    "\n",
    "cluster_only_labels = LabelAnalyzerBlock(\n",
    "    tag   = \"ClusterOnlyLabels\",\n",
    "    needs = (\"ClusterOnlyAnalyzer.clusters_path\",)   # ← csv path produced by label-mode run\n",
    ")\n",
    "\n",
    "no_cluster_labels = LabelAnalyzerBlock(\n",
    "    tag   = \"NoClusterLabels\",\n",
    "    needs = (\"NoClusterAnalyzer.clusters_path\",)  # ← csv path from pass-through analyzer\n",
    ")\n",
    "\n",
    "\n",
    "get_cluster_df = LoadDfBlock(\n",
    "    path_extension=Path(\"HNMFk\") / \"depth_0\" / 'Root',\n",
    "    recursive=False,\n",
    "    regex=r\"cluster_for_k=.*\\.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b style='color:green'>VultureClean</b> – all needs met<br><b style='color:green'>BeaverVocab</b> – all needs met<br><b style='color:green'>BeaverDW</b> – all needs met<br><b style='color:green'>NMFk</b> – all needs met<br><b style='color:green'>NMFAnalyzer</b> – all needs met<br><b style='color:green'>NMFLabels</b> – all needs met<br><b style='color:green'>HNMFk</b> – all needs met<br><b style='color:green'>HNMFAnalyzer</b> – all needs met<br><b style='color:green'>HNMFkLabels</b> – all needs met<br><b style='color:green'>NoClusterAnalyzer</b> – all needs met<br><b style='color:green'>NoClusterLabels</b> – all needs met<br><b style='color:green'>LoadDF</b> – all needs met<br><b style='color:green'>ClusterOnlyAnalyzer</b> – all needs met<br><b style='color:green'>ClusterOnlyLabels</b> – all needs met"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block (tag)                                   │ Needs (✓/✗)                                 │ Provides\n",
      "──────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "VultureCleanBlock (VultureClean)              │ df                                          │ ['df', 'vulture_steps']\n",
      "BeaverVocabBlock (BeaverVocab)                │ df                                          │ ['vocabulary']\n",
      "BeaverDocWordBlock (BeaverDW)                 │ df, vocabulary                              │ ['X']\n",
      "NMFkBlock (NMFk)                              │ X                                           │ ['nmfk_model', 'nmfk_model_path']\n",
      "ClusteringAnalyzerBlock (NMFAnalyzer)         │ df, nmfk_model, nmfk_model_path, vocabulary │ ['clusters_path']\n",
      "LabelAnalyzerBlock (NMFLabels)                │ NMFAnalyzer.clusters_path                   │ ['result', 'label_paths']\n",
      "HNMFkBlock (HNMFk)                            │ X                                           │ ['hnmfk_model', 'saved_path']\n",
      "ClusteringAnalyzerBlock (HNMFAnalyzer)        │ df, hnmfk_model, vocabulary                 │ ['clusters_path']\n",
      "LabelAnalyzerBlock (HNMFkLabels)              │ HNMFAnalyzer.clusters_path                  │ ['result', 'label_paths']\n",
      "ClusteringAnalyzerBlock (NoClusterAnalyzer)   │ df                                          │ ['clusters_path']\n",
      "LabelAnalyzerBlock (NoClusterLabels)          │ NoClusterAnalyzer.clusters_path             │ ['result', 'label_paths']\n",
      "LoadDfBlock (LoadDF)                          │ dir                                         │ ['df', 'df_paths']\n",
      "ClusteringAnalyzerBlock (ClusterOnlyAnalyzer) │ df                                          │ ['clusters_path']\n",
      "LabelAnalyzerBlock (ClusterOnlyLabels)        │ ClusterOnlyAnalyzer.clusters_path           │ ['result', 'label_paths']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "manager = BlockManager(\n",
    "    blocks = [\n",
    "        vulture_block,\n",
    "        vocab_block,\n",
    "        matrix_block,\n",
    "\n",
    "        factor_block,\n",
    "        nmfk_analyzer,\n",
    "        nmf_labels,\n",
    "\n",
    "        hfactor_block,\n",
    "        hnmfk_analyzer,\n",
    "        hnmfk_labels,\n",
    "\n",
    "        no_cluster_analyzer,\n",
    "        no_cluster_labels,\n",
    "\n",
    "        get_cluster_df,\n",
    "        extracted_cluster_only_nmfk_analyzer,\n",
    "        cluster_only_labels,\n",
    "    ],\n",
    "    databundle = bundle,\n",
    "    verbose    = True,\n",
    "    progress   = True,\n",
    "    capture_output = \"file\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶  [1/14] VultureClean …\n",
      "✓  [1/14] VultureClean finished in 0.01s\n",
      "▶  [2/14] BeaverVocab …\n",
      "✓  [2/14] BeaverVocab finished in 0.01s\n",
      "▶  [3/14] BeaverDW …\n",
      "✓  [3/14] BeaverDW finished in 0.01s\n",
      "▶  [4/14] NMFk …\n",
      "✓  [4/14] NMFk finished in 3.00s\n",
      "▶  [5/14] NMFAnalyzer …\n",
      "✓  [5/14] NMFAnalyzer finished in 21.28s\n",
      "▶  [6/14] NMFLabels …\n",
      "✓  [6/14] NMFLabels finished in 13.13s\n",
      "▶  [7/14] HNMFk …\n",
      "✓  [7/14] HNMFk finished in 0.00s\n",
      "▶  [8/14] HNMFAnalyzer …\n",
      "✓  [8/14] HNMFAnalyzer finished in 0.00s\n",
      "▶  [9/14] HNMFkLabels …\n",
      "✓  [9/14] HNMFkLabels finished in 17.50s\n",
      "▶  [10/14] NoClusterAnalyzer …\n",
      "✓  [10/14] NoClusterAnalyzer finished in 1.21s\n",
      "▶  [11/14] NoClusterLabels …\n",
      "✓  [11/14] NoClusterLabels finished in 0.97s\n",
      "▶  [12/14] LoadDF …\n",
      "✓  [12/14] LoadDF finished in 0.00s\n",
      "▶  [13/14] ClusterOnlyAnalyzer …\n",
      "✓  [13/14] ClusterOnlyAnalyzer finished in 13.45s\n",
      "▶  [14/14] ClusterOnlyLabels …\n",
      "✓  [14/14] ClusterOnlyLabels finished in 6.35s\n"
     ]
    }
   ],
   "source": [
    "bundle = manager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'BeaverDW': ['X']\n",
      "'BeaverVocab': ['vocabulary']\n",
      "'ClusterOnlyAnalyzer': ['clusters_path']\n",
      "'ClusterOnlyLabels': ['result', 'label_paths']\n",
      "'DataBundle': ['result_path']\n",
      "'Default': ['df']\n",
      "'HNMFAnalyzer': ['clusters_path']\n",
      "'HNMFk': ['hnmfk_model', 'saved_path']\n",
      "'HNMFkLabels': ['result', 'label_paths']\n",
      "'Init': ['save_path', 'dir']\n",
      "'LoadDF': ['df', 'df_paths']\n",
      "'NMFAnalyzer': ['clusters_path']\n",
      "'NMFLabels': ['result', 'label_paths']\n",
      "'NMFk': ['nmfk_model', 'nmfk_model_path']\n",
      "'NoClusterAnalyzer': ['clusters_path']\n",
      "'NoClusterLabels': ['result', 'label_paths']\n",
      "'VultureClean': ['df', 'vulture_steps']\n"
     ]
    }
   ],
   "source": [
    "bundle.print_tags_and_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NamespaceView(tag='NMFLabels', keys=['result', 'label_paths'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bundle.NMFLabels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'example_results/post_process_example/NMFk/cluster_for_k=20.csv': {17: 'Machine Learning for 19.0 Malware Detection Models',\n",
       "  19: 'Quantum Inspired Neural Network Optimization Techniques',\n",
       "  16: 'Reinforcement Learning for Robust Model Training',\n",
       "  18: 'Anomaly Detection Using 18.0 Matrix Models',\n",
       "  11: 'Malware Family Classification Using HNMFk Classifier Approach',\n",
       "  6: 'Neural Architecture Search for Dense Matrix Optimization on GPU Clusters',\n",
       "  9: 'Federated Learning for Collaborative Filtering Systems',\n",
       "  13: 'Anomaly Detection',\n",
       "  12: 'Malware Novelty Detection Using Hierarchical Tensor Factorization',\n",
       "  8: 'Machine Learning'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bundle.NMFLabels.result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NamespaceView(tag='HNMFkLabels', keys=['result', 'label_paths'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bundle.HNMFkLabels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_artic_fox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
